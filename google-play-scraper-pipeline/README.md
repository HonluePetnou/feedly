# Google Play Reviews Scraper & ETL Pipeline (Phase 3)

Ce projet constitue la **Phase 3** du dÃ©veloppement global. Il s'agit d'un module Python autonome conÃ§u pour **scraper**, **nettoyer** et **stocker** les avis d'applications depuis le Google Play Store.

L'objectif final est de fournir des donnÃ©es structurÃ©es et propres pour alimenter les modÃ¨les d'Intelligence Artificielle.

## ğŸ“‹ FonctionnalitÃ©s ClÃ©s

* **Extraction (Scraping) :** Collecte automatisÃ©e des avis via `google-play-scraper`.
* **Support Multi-Apps :** Gestion dynamique d'une liste d'applications Ã  surveiller.
* **Architecture Modulaire :** SÃ©paration claire entre Scraping, Nettoyage et Base de DonnÃ©es.
* **ORM Database :** Utilisation de SQLAlchemy pour interagir proprement avec la BDD.
* **Automatisation :** PrÃªt pour l'intÃ©gration de tÃ¢ches planifiÃ©es (Celery/Redis).

---

## ğŸ“‚ Structure du Projet

L'architecture sÃ©pare les responsabilitÃ©s pour faciliter la maintenance :

```text
google-play-scraper-pipeline/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.ini          # Configuration (Liste des Apps, paramÃ¨tres gÃ©nÃ©raux)
â”œâ”€â”€ data/                     # Stockage temporaire (utile pour le debug)
â”‚   â”œâ”€â”€ raw/                  # DonnÃ©es brutes (JSON/CSV avant nettoyage)
â”‚   â””â”€â”€ processed/            # DonnÃ©es nettoyÃ©es (prÃªtes pour l'insertion)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â””â”€â”€ scraper_module.py # LOGIQUE D'EXTRACTION (Google Play)
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ cleaner.py        # LOGIQUE DE TRANSFORMATION (Pandas)
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ db_manager.py     # Gestion de la connexion BDD (SQLAlchemy)
â”‚   â”‚   â””â”€â”€ models.py         # DÃ©finition des tables (SchÃ©mas)
â”‚   â”œâ”€â”€ tasks.py              # TÃ¢ches Celery pour l'automatisation
â”‚   â””â”€â”€ main_pipeline.py      # ORCHESTRATEUR (Point d'entrÃ©e du script)
â”œâ”€â”€ .env                      # Secrets (Mots de passe DB, API Keys)
â”œâ”€â”€ .gitignore                # Fichiers Ã  ignorer par Git
â”œâ”€â”€ README.md                 # Documentation
â””â”€â”€ requirements.txt          # DÃ©pendances Python
DÃ©tails des Modules
src/scraper/ : Interagit avec l'extÃ©rieur (le Store). Si l'API change, on modifie ici.

src/pipeline/ : Contient la logique de nettoyage des donnÃ©es (suppression emojis, formatage dates).

src/database/ : GÃ¨re tout ce qui touche au stockage. models.py dÃ©finit Ã  quoi ressemble une ligne de donnÃ©e, et db_manager.py gÃ¨re l'insertion.

ğŸš€ Installation & Configuration
1. PrÃ©requis
Python 3.9+

Une base de donnÃ©es (PostgreSQL recommandÃ© ou MySQL)

Redis (optionnel, uniquement pour le mode planifiÃ©)

2. Installation
Bash

# CrÃ©er et activer l'environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows: .\venv\Scripts\Activate.ps1 (powershell) || venv\Scripts\activate (cmd || git bash)

# Installer les dÃ©pendances
pip install -r requirements.txt
3. Configuration
CrÃ©ez un fichier .env Ã  la racine :

Ini, TOML

DB_HOST=localhost
DB_NAME=reviews_db
DB_USER=postgres
DB_PASSWORD=secret
Configurez les cibles dans config/settings.ini :

Ini, TOML

[SCRAPING]
target_apps = com.whatsapp, com.instagram.android
ğŸƒâ€â™‚ï¸ Lancement
Pour lancer le pipeline complet manuellement :

Bash

python src/main_pipeline.py




DerniÃ¨re mise Ã  jour : Novembre 2025